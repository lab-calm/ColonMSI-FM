{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8981974,"sourceType":"datasetVersion","datasetId":5408874},{"sourceId":8982755,"sourceType":"datasetVersion","datasetId":5409447},{"sourceId":8982844,"sourceType":"datasetVersion","datasetId":5409520},{"sourceId":8988696,"sourceType":"datasetVersion","datasetId":5413669},{"sourceId":9008334,"sourceType":"datasetVersion","datasetId":5427164},{"sourceId":9011019,"sourceType":"datasetVersion","datasetId":5429155},{"sourceId":9011270,"sourceType":"datasetVersion","datasetId":5429331},{"sourceId":9011277,"sourceType":"datasetVersion","datasetId":5429335},{"sourceId":9056071,"sourceType":"datasetVersion","datasetId":5460559},{"sourceId":9056255,"sourceType":"datasetVersion","datasetId":5460683}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport time\nimport random\nimport PIL.Image as Image\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nimport torch.nn.functional as F\nimport torch.utils.data as data\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nfrom sklearn.metrics import roc_curve, auc , f1_score, accuracy_score\nfrom sklearn.metrics import precision_recall_curve, average_precision_score\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\nImage.MAX_IMAGE_PIXELS = None","metadata":{"execution":{"iopub.status.busy":"2024-07-29T08:04:51.648511Z","iopub.execute_input":"2024-07-29T08:04:51.648897Z","iopub.status.idle":"2024-07-29T08:04:55.288431Z","shell.execute_reply.started":"2024-07-29T08:04:51.648866Z","shell.execute_reply":"2024-07-29T08:04:55.287351Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_dir = '/kaggle/input/final-label/FINAL'\ncsv_file='/kaggle/input/wsi-csv/selected_data.csv'\n\n#val_lib = ''\nval_dir = '/kaggle/input/label-val/LABEL_CHECKING'\n\nproject='train_convergence'             \noutput = os.path.join('/kaggle/working')\n\nbatch_size = 1\nnepochs = 5\n\ntest_every = 1           # related to validation set, if needed\nweights = 0.5            # weight of a positive class if imbalanced\n\nlr = 1e-4                # learning rate\nweight_decay = 1e-4      # l2 regularzation weight\n \nbest_auc_v = 0           # related to validation set, if needed","metadata":{"execution":{"iopub.status.busy":"2024-07-29T08:05:44.416249Z","iopub.execute_input":"2024-07-29T08:05:44.416968Z","iopub.status.idle":"2024-07-29T08:05:44.423162Z","shell.execute_reply.started":"2024-07-29T08:05:44.416930Z","shell.execute_reply":"2024-07-29T08:05:44.422163Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#dataloader\ndef Image_filter(folder_path,dimensions ,threshold=3000):\n    print(\"DIMENSIONS: \",dimensions)\n    filtered_images = []\n    if dimensions:\n        filtered_images.append(dimensions[0])\n        prev_height, prev_width = dimensions[0][:2]\n        #print(\"First Image : \",prev_height,\"  \",prev_width)\n        \n    for height, width, img_file in dimensions[1:]:\n        #print(\"Height : Width : \",height,\"  \",width,\" \",img_file)\n        #print(\"Filtered Images : \",filtered_images)\n        if abs(height - prev_height) <= threshold:\n            filtered_images.append((height, width, img_file))\n            i = 0\n            while i < len(filtered_images) - 1:\n                if abs(filtered_images[i][0] - filtered_images[i + 1][0]) > threshold:\n                    res = filtered_images.pop(i)\n                    print(\"Popped : \", res)\n                else:\n                    i += 1\n        else:\n            if filtered_images and abs(height - filtered_images[-1][0]) < threshold:\n                filtered_images.append((height, width, img_file))\n            if filtered_images[-1][0] > height:\n                res = filtered_images.pop()\n                filtered_images.append((height, width, img_file))\n                print(\"Pop : \", res)\n                \n        if not filtered_images:\n                filtered_images.append((height, width, img_file))\n\n        prev_height, prev_width = height, width\n\n    return filtered_images\n\ndef get_image_dimensions(folder_path):\n    image_files = os.listdir(folder_path)\n    dimensions = []\n\n    for img_file in image_files:\n        img_path = os.path.join(folder_path, img_file)\n        try:\n            img = cv2.imread(img_path)\n\n            if img is None:\n                print(f\"Error reading image {img_path}\")\n                continue\n\n            height, width = img.shape[:2]\n            dimensions.append((height, width, img_file))\n        except Exception as e:\n            print(f\"Exception occurred while reading image {img_path}: {e}\")\n            continue\n\n    return dimensions\n\ndef zero_pad_and_convert_to_tensor(folder_path, image_names, max_height, max_width):\n    padded_images = []\n\n    for img_name in image_names:\n        img_path = os.path.join(folder_path, img_name)\n        try:\n            img = cv2.imread(img_path)\n        \n            if img is None:\n                print(f\"Error reading image {img_path}\")\n                continue\n        \n            height, width = img.shape[:2]\n            pad_height = max_height - height\n            pad_width = max_width - width\n\n            padded_img = np.pad(img, ((0, pad_height), (0, pad_width), (0, 0)), mode='constant', constant_values=0)\n            padded_images.append(padded_img)\n        except Exception as e:\n            print(f\"Exception occurred while processing image {img_path}: {e}\")\n            continue\n\n    tensors = [torch.tensor(img, dtype=torch.float32).permute(2, 0, 1) for img in padded_images]\n    return tensors\n\nclass MPdataset(data.Dataset):\n    def __init__(self, path_dir=None, csv_file=None, transform=None, mult=2, is_validation=False):\n        self.folder_path = path_dir\n        if not is_validation:\n            image_files = os.listdir(self.folder_path)\n            dimensions = []\n\n            for img_file in image_files:\n                img_path = os.path.join(self.folder_path, img_file)\n                try:\n                    img = cv2.imread(img_path)\n\n                    if img is None:\n                        print(f\"Error reading image {img_path}\")\n                        continue\n\n                    height, width = img.shape[:2]\n                    dimensions.append((height, width, img_file))\n                    #print(\"Dimesions: \",dimensions)\n                except Exception as e:\n                    print(f\"Exception occurred while reading image {img_path}: {e}\")\n                    continue\n\n            dimensions.sort(reverse=True, key=lambda x: x[0])\n            \n            filtered_images = Image_filter(self.folder_path,dimensions)\n            #print(\"FILTERED IMAGES:\")\n        else:\n            filtered_images = get_image_dimensions(self.folder_path)\n\n        if not filtered_images:\n            print(\"No images left after filtering.\")\n        else:\n            for height, width, filename in filtered_images:\n                print(f\"- {filename} ({height}x{width})\")\n            print(\"****************************\")\n                \n        max_height = max(dim[0] for dim in filtered_images)\n        max_width = max(dim[1] for dim in filtered_images)\n\n        filtered_image_names = [img[2] for img in filtered_images]\n        self.tensors = zero_pad_and_convert_to_tensor(self.folder_path, filtered_image_names, max_height, max_width)\n        self.image_names = filtered_image_names\n        \n        # Read CSV file and match names to get labels\n        if csv_file:\n            labels_df = pd.read_csv(csv_file)\n            labels_dict = {row['PATIENT'][:12]: 1 if row['isMSIH'] == 'MSIH' else 0 for idx, row in labels_df.iterrows()}\n            self.targets = [labels_dict.get(img_name[:12], 0) for img_name in self.image_names]\n            print(\"SELF TARGETS : \",self.targets)\n        else:\n            self.targets = [0] * len(self.tensors)  # Default to zero if no CSV provided\n\n        self.transform = transform\n        self.mult = mult\n        self.mode = None\n\n    def setmode(self, mode):\n        self.mode = mode\n\n    def maketraindata(self, idxs):\n        self.t_data = [(self.image_names[x], self.tensors[x], self.targets[x]) for x in idxs]\n\n    def shuffletraindata(self):\n        self.t_data = random.sample(self.t_data, len(self.t_data))\n\n    def __getitem__(self, index):\n        if self.mode == 1:\n            img = self.tensors[index]\n            target = self.targets[index]\n            if self.transform is not None:\n                img = self.transform(img)\n            return img, target\n        elif self.mode == 2:\n            img_name, img, target = self.t_data[index]\n            if self.transform is not None:\n                img = self.transform(img)\n            return img, target\n\n    def __len__(self):\n        if self.mode == 1:\n            return len(self.tensors)\n        elif self.mode == 2:\n            return len(self.t_data)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-29T08:05:02.085536Z","iopub.execute_input":"2024-07-29T08:05:02.085881Z","iopub.status.idle":"2024-07-29T08:05:02.116515Z","shell.execute_reply.started":"2024-07-29T08:05:02.085854Z","shell.execute_reply":"2024-07-29T08:05:02.115609Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def calc_roc_auc(target, prediction):\n    fpr, tpr, thresholds = roc_curve(target, prediction)\n    roc_auc = auc(fpr, tpr)\n    return roc_auc\n\ndef calculate_accuracy(output, target):\n    #print(\"Output: \",output)\n    #print(\"Targets : \",target)\n    # Since output is a probability, threshold at 0.5 to get class predictions\n    preds = (output > 0.5).float().cpu()\n    #print(\"preds: \",preds)\n    target = target.cpu()\n    acc = accuracy_score(target.view_as(preds), preds)\n    return acc\n\n\n# also add F1 score\ndef calculate_f1(output, target):\n    # Convert probabilities to binary predictions using a threshold of 0.5\n    preds = (output > 0.5).float().cpu()\n    target = target.cpu()\n    \n    # Calculate F1 score\n    f1 = f1_score(target.view_as(preds), preds)\n    return f1\n\n\n#function to calculate mean of data grouped per slide, used for aggregating tile scores into slide score\ndef group_avg(groups, data):\n    order = np.lexsort((data, groups))\n    groups = groups[order]\n    data = data[order]\n    unames, idx, counts = np.unique(groups, return_inverse=True, return_counts=True)\n    group_sum = np.bincount(idx, weights=data)\n    group_average = group_sum / counts\n    return group_average\n\n#function to find index of max value in data grouped per slide\ndef group_max(groups, data, nmax):\n    out = np.empty(nmax)\n    out[:] = np.nan\n    order = np.lexsort((data, groups))\n    groups = groups[order]\n    data = data[order]\n    index = np.empty(len(groups), 'bool')\n    index[-1] = True\n    index[:-1] = groups[1:] != groups[:-1]\n    out[groups[index]] = data[index]\n    return out\n\ndef Pk_score(all_labels, all_probs):\n    if isinstance(all_labels, list):\n        all_labels = np.array(all_labels)\n    if isinstance(all_probs, list):\n        all_probs = np.array(all_probs)\n        \n    all_probs = np.ravel(all_probs) \n    \n    # Print shapes and data to debug\n    #print(\"all_probs:\", all_probs)\n    #print(\"all_probs shape:\", all_probs.shape)\n    #print(\"all_labels:\", all_labels)\n    #print(\"all_labels shape:\", all_labels.shape)\n\n    # Ensure that all_labels and all_probs have the same length\n    if len(all_labels) != len(all_probs):\n        raise ValueError(\"Length of all_labels and all_probs must be the same\")\n    \n    # Check if all_labels contains both classes\n    if np.unique(all_labels).size < 2:\n        raise ValueError(\"all_labels must contain both positive and negative samples\")\n\n    # Calculate precision-recall curve\n    precision, recall, _ = precision_recall_curve(all_labels, all_probs)\n    #print(\"Precision:\", precision)\n    #print(\"Recall:\", recall)\n\n    # Calculate average precision score\n    try:\n        auc_pk_score = average_precision_score(all_labels, all_probs)\n        if np.isnan(auc_pk_score):\n            raise ValueError(\"Calculated AUC Pk-Score is NaN\")\n    except ValueError as e:\n        print(f\"Error calculating average precision score: {e}\")\n        auc_pk_score = None\n    \n    print(\"AUC Pk-Score:\", auc_pk_score)\n    \n    return auc_pk_score\n","metadata":{"execution":{"iopub.status.busy":"2024-07-29T08:05:05.077773Z","iopub.execute_input":"2024-07-29T08:05:05.078160Z","iopub.status.idle":"2024-07-29T08:05:05.093028Z","shell.execute_reply.started":"2024-07-29T08:05:05.078133Z","shell.execute_reply":"2024-07-29T08:05:05.091963Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#baseline cnn model to fine tune\nmodel = models.resnet18(True)\nmodel.fc = nn.Linear(model.fc.in_features, 1)\nmodel.cuda()\n\nif weights==0.5:\n    criterion = nn.CrossEntropyLoss().cuda()\nelse:\n    w = torch.Tensor([1-weights,weights])\n    criterion = nn.CrossEntropyLoss(w).cuda()\n    \noptimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=lr)\n\ncudnn.benchmark = True","metadata":{"execution":{"iopub.status.busy":"2024-07-29T08:05:08.465894Z","iopub.execute_input":"2024-07-29T08:05:08.466564Z","iopub.status.idle":"2024-07-29T08:05:08.928721Z","shell.execute_reply.started":"2024-07-29T08:05:08.466532Z","shell.execute_reply":"2024-07-29T08:05:08.927863Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"model = models.resnet18(True)\nmodel.fc = nn.Linear(model.fc.in_features, 1)\nmodel.cuda()\n\nif weights == 0.5:\n    criterion = nn.BCEWithLogitsLoss().cuda()\nelse:\n    w = torch.Tensor([1 - weights, weights])\n    criterion = nn.CrossEntropyLoss(w).cuda()\n\noptimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=lr)\n\ncudnn.benchmark = True\n\nnormalize = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.1, 0.1, 0.1])\n\ntrans = transforms.Compose([\n    normalize,\n])\n\ntrans_Valid = transforms.Compose([\n    normalize,\n])\n\ntrain_dset = MPdataset(path_dir=train_dir, csv_file=csv_file, transform=trans, is_validation=False)\ntrain_loader = torch.utils.data.DataLoader(\n    train_dset,\n    batch_size=batch_size, shuffle=False,\n    num_workers=4, pin_memory=False\n)\n\nif val_dir:\n    val_dset = MPdataset(path_dir=val_dir, csv_file=csv_file, transform=trans_Valid, is_validation=True)\n    val_loader = torch.utils.data.DataLoader(\n        val_dset,\n        batch_size=batch_size, shuffle=False,\n        num_workers=4, pin_memory=False\n    )\n\n# Open output files for convergence metrics\noutput_dir = '/kaggle/working/'\nos.makedirs(output_dir, exist_ok=True)\n\nwith open(os.path.join(output_dir, 'train_convergence.csv'), 'w') as fconv:\n    fconv.write('epoch,loss,accuracy,f1,Roc_auc,average_precision_score\\n')\n\nwith open(os.path.join(output_dir, 'valid_convergence.csv'), 'w') as fconv:\n    fconv.write('epoch,accuracy,Roc_auc,f1,average_precision_score\\n')\n\ntrain_dset.setmode(1)\n# Prepare all tiles of training set slides\nnum_tiles = len(train_dset)  # Assuming len(train_dset) gives the number of tiles\nprint(\"TILES Selected : \",num_tiles)\n\ntrain_dset.maketraindata(np.arange(num_tiles))","metadata":{"execution":{"iopub.status.busy":"2024-07-29T08:05:56.762621Z","iopub.execute_input":"2024-07-29T08:05:56.762966Z","iopub.status.idle":"2024-07-29T08:06:00.899563Z","shell.execute_reply.started":"2024-07-29T08:05:56.762939Z","shell.execute_reply":"2024-07-29T08:06:00.898583Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"DIMENSIONS:  [(4119, 3003, 'TCGA-A6-5657_nonMSIH6.png'), (3163, 3195, 'TCGA-A6-2681_nonMSIH3.png'), (3074, 2690, 'TCGA-A6-5661_MSIH7.png')]\n- TCGA-A6-5657_nonMSIH6.png (4119x3003)\n- TCGA-A6-2681_nonMSIH3.png (3163x3195)\n- TCGA-A6-5661_MSIH7.png (3074x2690)\n****************************\nSELF TARGETS :  [0, 0, 1]\n- TCGA-A6-5665_MSIH8.png (4044x2479)\n- TCGA-A6-5666_nonMSIH9.png (5232x4554)\n****************************\nSELF TARGETS :  [1, 0]\nTILES Selected :  3\n","output_type":"stream"}]},{"cell_type":"code","source":"def train(run, loader, model, criterion, optimizer):\n    model.train()\n    running_loss = 0.0\n    running_acc = 0.0\n    all_outputs = []\n    all_targets = []\n\n    for i, (input, target) in enumerate(loader):\n        input = input.cuda()\n        target = target.cuda().float().view(-1, 1)  # Ensure target is of the correct type and shape\n        \n        # Debugging: Print shapes of inputs and targets\n        #print(f\"Input shape: {input.shape}, Target shape: {target.shape}\")\n        \n        # Forward pass\n        output = model(input)\n        \n        # Calculate loss\n        #print(\"OUTPUTTTTTTTTT: \",output)\n        #print(\"TARGETTTTTTTTT: \",target)\n        \n        loss = criterion(output, target)\n        \n        # Debugging: Print loss value\n        #print(f\"Loss: {loss.item()}\")\n        \n        # Backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Accumulate loss and accuracy\n        running_loss += loss.item() * input.size(0)\n        \n        # Convert output to probabilities\n        probs = torch.sigmoid(output)\n        \n        # Predictions based on threshold of 0.5\n        preds = (probs > 0.5).float()\n        \n        # Calculate accuracy\n        acc = calculate_accuracy(preds, target)\n        running_acc += acc * input.size(0)\n        \n        all_outputs.append(probs)\n        all_targets.append(target)\n\n        if i % 100 == 0:\n            # Compute metrics on the current batch\n            batch_f1 = calculate_f1(preds, target)\n            batch_auc_roc = calc_roc_auc(target.cpu().numpy(), probs.detach().cpu().numpy())\n            \n            # Print epoch training loss, accuracy, F1, and ROC-AUC for the current batch\n            print('Training\\tEpoch: [{:3d}/{:3d}]\\tBatch: [{:3d}/{}]\\tLoss: {:0.4f}\\tAccuracy: {:0.2f}%\\tF1: {:0.2f}\\tROC-AUC: {:0.2f}'\n                .format(run + 1, nepochs, i + 1, len(loader), \n                        running_loss / ((i + 1) * input.size(0)), \n                        (100 * running_acc) / ((i + 1) * input.size(0)), \n                        batch_f1, batch_auc_roc))\n\n    # Compute metrics for the entire epoch\n    all_outputs = torch.cat(all_outputs)\n    all_targets = torch.cat(all_targets)\n    \n    # For the full dataset, calculate metrics using concatenated outputs and targets\n    epoch_f1 = calculate_f1((all_outputs > 0.5).float(), all_targets)\n    epoch_auc_roc = calc_roc_auc(all_targets.cpu().numpy(), all_outputs.detach().cpu().numpy())\n    epoch_acc = (100 * running_acc) / len(loader.dataset)\n    epoch_pk_score = Pk_score(all_targets.cpu().numpy(), all_outputs.detach().cpu().numpy())\n\n    return running_loss / len(loader.dataset), epoch_acc, epoch_f1, epoch_auc_roc, epoch_pk_score\n\n\n\nimport torch.nn.functional as F\n\ndef inference(run, loader, model):\n    model.eval()\n    running_acc = 0.0\n    all_outputs = []\n    all_targets = []\n    \n    batch_size = loader.batch_size\n\n    probs = torch.FloatTensor(len(loader.dataset))\n    preds = torch.FloatTensor(len(loader.dataset))\n    \n    with torch.no_grad():\n        for i, (input, target) in enumerate(loader):\n            input = input.cuda()\n            target = target.cuda()\n            \n            logits = model(input)\n            y = torch.sigmoid(logits).view(-1)  # Flatten y\n\n            # Get binary predictions\n            pr = (y > 0.5).float()            \n            #print(\"Y : \",y)\n            #print(\"Pr : \",pr)\n            # Ensure the size matches\n            preds[i * batch_size:i * batch_size + input.size(0)] = pr.cpu().detach()\n            probs[i * batch_size:i * batch_size + input.size(0)] = y.cpu().detach()\n            #print(\"PROBSSSSSSSSSSS : \",probs)\n            \n            # Debug output\n            #print(\"Labels:\", target.cpu().numpy())\n            #print(\"Probabilities:\", y.cpu().numpy())\n            \n            acc = calculate_accuracy(pr, target)\n            running_acc += acc * input.size(0)\n            \n            all_outputs.append(logits)\n            all_targets.append(target)\n\n            if i % 100 == 0:\n                batch_f1 = calculate_f1(pr, target)\n                batch_auc_roc = calc_roc_auc(target.cpu().numpy(), y.cpu().numpy())\n                #batch_pk_score = Pk_score(target.cpu().numpy(), pr.cpu().numpy())\n                \n                print('Inference\\tRun: [{:3d}]\\tBatch: [{:3d}/{}]\\tAccuracy: {:0.2f}%\\tF1: {:0.2f}\\tROC-AUC: {:0.2f}'\n                      .format(run + 1, i + 1, len(loader), \n                              acc, batch_f1, batch_auc_roc))\n\n    all_outputs = torch.cat(all_outputs)\n    all_targets = torch.cat(all_targets)\n    \n    overall_acc = (100 * running_acc) / len(loader.dataset)\n    overall_f1 = calculate_f1(preds, all_targets)\n    overall_auc_roc = calc_roc_auc(all_targets.cpu().numpy(), probs.cpu().numpy())\n    overall_pk_score = Pk_score(all_targets.cpu().numpy(), probs.cpu().numpy())\n    \n    print('Inference\\tRun: [{:3d}]\\tOverall\\tAccuracy: {:0.2f}%\\tF1: {:0.2f}\\tROC-AUC: {:0.2f}\\tPk-Score: {:0.2f}'\n          .format(run + 1, overall_acc, overall_f1, overall_auc_roc, overall_pk_score))\n\n    return probs.cpu().numpy(), overall_acc, preds.cpu().numpy(), overall_f1, overall_auc_roc, overall_pk_score\n","metadata":{"execution":{"iopub.status.busy":"2024-07-29T08:06:13.706341Z","iopub.execute_input":"2024-07-29T08:06:13.706694Z","iopub.status.idle":"2024-07-29T08:06:13.729030Z","shell.execute_reply.started":"2024-07-29T08:06:13.706667Z","shell.execute_reply":"2024-07-29T08:06:13.727959Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Measure data loading time\nstart_time = time.time()\n\n# Initialize best AUC value\nbest_auc_v = 0.0\n\n# Loop through epochs\nfor epoch in range(nepochs):\n    train_dset.shuffletraindata()\n    train_dset.setmode(2)\n    \n    # Train the model and get the metrics\n    loss, acc, f1, auc_roc, auc_pk_score = train(epoch, train_loader, model, criterion, optimizer)\n    \n    # Measure elapsed time so far\n    print(\"--- {:0.2f} minutes ---\".format((time.time() - start_time)/60.))\n    \n    # Print training metrics\n    print('Training\\tEpoch: [{}/{}]\\tLoss: {:0.4f}\\tAccuracy: {:0.4f}\\tF1: {:0.4f}\\tROC-AUC: {:0.4f}\\tPk-Score: {:0.4f}'\n          .format(epoch + 1, nepochs, loss, acc, f1, auc_roc, auc_pk_score))\n    \n    # Log training metrics to CSV\n    with open(os.path.join(output, 'train_convergence.csv'), 'a') as fconv:\n        fconv.write('{},{:0.4f},{:0.4f},{:0.4f},{:0.4f},{:0.4f}\\n'.format(epoch + 1, loss, acc, f1, auc_roc, auc_pk_score))\n    \n    # Validation if needed\n    if val_dir and (epoch+1) % test_every == 0:\n        val_dset.setmode(1)\n        val_probs, val_acc, val_preds, val_f1, val_auc_roc,val_pk_score  = inference(epoch, val_loader, model)\n        \n        # Compute additional metrics using calculate_auc_and_f1\n        auc_pk_score = Pk_score(val_dset.targets, val_probs)\n\n        # Update best AUC\n        best_auc_v = max(best_auc_v, val_auc_roc)\n        \n        # Print validation metrics including PR-AUC\n        print('Validation\\tEpoch: [{}/{}]\\tval_acc: {:0.4f}\\tROC-AUC: {:0.4f}\\tPR-AUC: {:0.4f}\\tbest so far: {:0.4f}'\n              .format(epoch + 1, nepochs, val_acc, val_auc_roc, val_pk_score, best_auc_v))\n        \n        # Log validation metrics to CSV\n        with open(os.path.join(output, 'valid_convergence.csv'), 'a') as fconv:\n            fconv.write('{},{:0.4f},{:0.4f},{:0.4f},{:0.4f}\\n'.format(epoch+1, val_acc, val_auc_roc,val_f1,val_pk_score))\n        \n        # Save best model\n        if val_auc_roc > best_auc_v:\n            best_auc_v = val_auc_roc\n            obj = {\n                'epoch': epoch+1,\n                'state_dict': model.state_dict(),\n                'best_auc_v': best_auc_v,\n                'optimizer': optimizer.state_dict()\n            }\n            torch.save(obj, os.path.join(output, 'checkpoint_best.pth'))\n    \n    # Measure accumulated elapsed time so far\n    print(\"--- {:0.2f} minutes ---\".format((time.time() - start_time)/60.))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-29T08:06:15.954271Z","iopub.execute_input":"2024-07-29T08:06:15.954880Z","iopub.status.idle":"2024-07-29T08:07:47.907752Z","shell.execute_reply.started":"2024-07-29T08:06:15.954847Z","shell.execute_reply":"2024-07-29T08:07:47.906231Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1020: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Training\tEpoch: [  1/  5]\tBatch: [  1/3]\tLoss: 0.8848\tAccuracy: 0.00%\tF1: 0.00\tROC-AUC: nan\nAUC Pk-Score: 0.3333333333333333\n--- 1.13 minutes ---\nTraining\tEpoch: [1/5]\tLoss: 0.6881\tAccuracy: 66.6667\tF1: 0.0000\tROC-AUC: 0.0000\tPk-Score: 0.3333\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1020: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Inference\tRun: [  1]\tBatch: [  1/2]\tAccuracy: 0.00%\tF1: 0.00\tROC-AUC: nan\nAUC Pk-Score: 1.0\nInference\tRun: [  1]\tOverall\tAccuracy: 50.00%\tF1: 0.00\tROC-AUC: 1.00\tPk-Score: 1.00\nAUC Pk-Score: 1.0\nValidation\tEpoch: [1/5]\tval_acc: 50.0000\tROC-AUC: 1.0000\tPR-AUC: 1.0000\tbest so far: 1.0000\n--- 1.24 minutes ---\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1020: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Training\tEpoch: [  2/  5]\tBatch: [  1/3]\tLoss: 0.8259\tAccuracy: 0.00%\tF1: 0.00\tROC-AUC: nan\nAUC Pk-Score: 1.0\n--- 1.30 minutes ---\nTraining\tEpoch: [2/5]\tLoss: 0.6208\tAccuracy: 66.6667\tF1: 0.0000\tROC-AUC: 1.0000\tPk-Score: 1.0000\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1020: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Inference\tRun: [  2]\tBatch: [  1/2]\tAccuracy: 0.00%\tF1: 0.00\tROC-AUC: nan\nAUC Pk-Score: 1.0\nInference\tRun: [  2]\tOverall\tAccuracy: 50.00%\tF1: 0.00\tROC-AUC: 1.00\tPk-Score: 1.00\nAUC Pk-Score: 1.0\nValidation\tEpoch: [2/5]\tval_acc: 50.0000\tROC-AUC: 1.0000\tPR-AUC: 1.0000\tbest so far: 1.0000\n--- 1.33 minutes ---\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Training\tEpoch: [  3/  5]\tBatch: [  1/3]\tLoss: 0.4742\tAccuracy: 100.00%\tF1: 0.00\tROC-AUC: nan\nAUC Pk-Score: 1.0\n--- 1.39 minutes ---\nTraining\tEpoch: [3/5]\tLoss: 0.5416\tAccuracy: 66.6667\tF1: 0.0000\tROC-AUC: 1.0000\tPk-Score: 1.0000\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1020: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Inference\tRun: [  3]\tBatch: [  1/2]\tAccuracy: 0.00%\tF1: 0.00\tROC-AUC: nan\nAUC Pk-Score: 1.0\nInference\tRun: [  3]\tOverall\tAccuracy: 50.00%\tF1: 0.00\tROC-AUC: 1.00\tPk-Score: 1.00\nAUC Pk-Score: 1.0\nValidation\tEpoch: [3/5]\tval_acc: 50.0000\tROC-AUC: 1.0000\tPR-AUC: 1.0000\tbest so far: 1.0000\n--- 1.42 minutes ---\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1020: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Training\tEpoch: [  4/  5]\tBatch: [  1/3]\tLoss: 0.6646\tAccuracy: 100.00%\tF1: 1.00\tROC-AUC: nan\nAUC Pk-Score: 1.0\n--- 1.48 minutes ---\nTraining\tEpoch: [4/5]\tLoss: 0.4450\tAccuracy: 100.0000\tF1: 1.0000\tROC-AUC: 1.0000\tPk-Score: 1.0000\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1020: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Inference\tRun: [  4]\tBatch: [  1/2]\tAccuracy: 0.00%\tF1: 0.00\tROC-AUC: nan\nAUC Pk-Score: 1.0\nInference\tRun: [  4]\tOverall\tAccuracy: 50.00%\tF1: 0.00\tROC-AUC: 1.00\tPk-Score: 1.00\nAUC Pk-Score: 1.0\nValidation\tEpoch: [4/5]\tval_acc: 50.0000\tROC-AUC: 1.0000\tPR-AUC: 1.0000\tbest so far: 1.0000\n--- 1.51 minutes ---\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m train_dset\u001b[38;5;241m.\u001b[39msetmode(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Train the model and get the metrics\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m loss, acc, f1, auc_roc, auc_pk_score \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Measure elapsed time so far\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- \u001b[39m\u001b[38;5;132;01m{:0.2f}\u001b[39;00m\u001b[38;5;124m minutes ---\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat((time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60.\u001b[39m))\n","Cell \u001b[0;32mIn[9], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(run, loader, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m      5\u001b[0m all_outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m all_targets \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (\u001b[38;5;28minput\u001b[39m, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     10\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mcuda()\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Ensure target is of the correct type and shape\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n","File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n","File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n","File \u001b[0;32m/opt/conda/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Define paths\noutput_dir = '/kaggle/working/'\ntrain_csv_path = os.path.join(output_dir, 'train_convergence.csv')\nvalid_csv_path = os.path.join(output_dir, 'valid_convergence.csv')\n\n# Read CSV files\ntrain_df = pd.read_csv(train_csv_path)\nvalid_df = pd.read_csv(valid_csv_path)\n\n# Plot training metrics\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(train_df['epoch'], train_df['loss'], label='Training Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training Loss over Epochs')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(train_df['epoch'], train_df['accuracy'], label='Training Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Training Accuracy over Epochs')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n# Plot validation metrics\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(valid_df['epoch'], valid_df['Acc'], label='Accuracy ')\nplt.xlabel('Epoch')\nplt.ylabel('acc')\nplt.title('Accuracy over Epochs')\nplt.legend()\n\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}