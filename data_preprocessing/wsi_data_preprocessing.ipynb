{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import cv2\n",
    "# The path can also be read from a config file, etc.\n",
    "OPENSLIDE_PATH = r'E:\\KSA Project\\data_preprocessing\\openslide-bin-4.0.0.3-windows-x64\\bin'\n",
    "\n",
    "if hasattr(os, 'add_dll_directory'):\n",
    "    # Windows\n",
    "    with os.add_dll_directory(OPENSLIDE_PATH):\n",
    "        import openslide\n",
    "else:\n",
    "    import openslide\n",
    "from WSI_Stiching_Code.wsi_core.WholeSlideImage import WholeSlideImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "input_dir = r'E:\\KSA Project\\dataset\\svs_files'\n",
    "output_dir = r'E:\\KSA Project\\dataset\\downsample_crop'\n",
    "target_size = (1024, 1024)  # Example target size for resizing if required. \n",
    "label = 'example_label'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Downsampling of the WSI images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing WSI: TCGA-3L-AA1B_nonMSIH.svs\n",
      "Magnification: 40x\n",
      "Scale factor: 8.0\n",
      "Original dimensions: (95615, 74462)\n",
      "Using scale factor: 8.0 the best level 1 with downsample factor 4.000116473747436\n",
      "Downsampled dimensions: 11951 x 9307\n",
      "Downsampled region dimensions using read region: (23903, 18615)\n",
      "Downsampled dimensions using resize: (11951, 9307)\n",
      "Processing WSI: TCGA-A6-2671_nonMSIH.svs\n",
      "Magnification: 40x\n",
      "Scale factor: 8.0\n",
      "Original dimensions: (101680, 36748)\n",
      "Using scale factor: 8.0 the best level 1 with downsample factor 4.0\n",
      "Downsampled dimensions: 12710 x 4593\n",
      "Downsampled region dimensions using read region: (25420, 9187)\n",
      "Downsampled dimensions using resize: (12710, 4593)\n",
      "Processing WSI: TCGA-A6-2675_nonMSIH.svs\n",
      "Magnification: 40x\n",
      "Scale factor: 8.0\n",
      "Original dimensions: (157316, 21227)\n",
      "Using scale factor: 8.0 the best level 1 with downsample factor 4.000282698831512\n",
      "Downsampled dimensions: 19664 x 2653\n",
      "Downsampled region dimensions using read region: (39329, 5306)\n",
      "Downsampled dimensions using resize: (19664, 2653)\n",
      "Processing WSI: TCGA-A6-3807_nonMSIH.svs\n",
      "Magnification: 40x\n",
      "Scale factor: 8.0\n",
      "Original dimensions: (151560, 46538)\n",
      "Using scale factor: 8.0 the best level 1 with downsample factor 4.0000859549596015\n",
      "Downsampled dimensions: 18945 x 5817\n",
      "Downsampled region dimensions using read region: (37890, 11634)\n",
      "Downsampled dimensions using resize: (18945, 5817)\n",
      "Processing WSI: TCGA-AA-3489_nonMSIH.svs\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "WSI does not contain objective power information.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m             wsi_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, wsi_file)\n\u001b[0;32m     50\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing WSI: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwsi_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 51\u001b[0m             \u001b[43mdownsample_and_resize_wsi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwsi_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished DownSampling!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m, in \u001b[0;36mdownsample_and_resize_wsi\u001b[1;34m(wsi_path, output_dir, label, target_size)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownsample_and_resize_wsi\u001b[39m(wsi_path, output_dir, label,target_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     12\u001b[0m     slide \u001b[38;5;241m=\u001b[39m openslide\u001b[38;5;241m.\u001b[39mOpenSlide(wsi_path)\n\u001b[1;32m---> 13\u001b[0m     mag \u001b[38;5;241m=\u001b[39m \u001b[43mget_wsi_magnification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslide\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMagnification: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m     scale_factor \u001b[38;5;241m=\u001b[39m mag \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m5.0\u001b[39m\n",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m, in \u001b[0;36mget_wsi_magnification\u001b[1;34m(slide)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(objective_power)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWSI does not contain objective power information.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: WSI does not contain objective power information."
     ]
    }
   ],
   "source": [
    "def get_wsi_magnification(slide):\n",
    "    \"\"\"\n",
    "    Get the magnification of a WSI image using OpenSlide properties.\n",
    "    \"\"\"\n",
    "    objective_power = slide.properties.get('openslide.objective-power')\n",
    "    if objective_power:\n",
    "        return int(objective_power)\n",
    "    else:\n",
    "        raise ValueError(\"WSI does not contain objective power information.\")\n",
    "\n",
    "def downsample_and_resize_wsi(wsi_path, output_dir, label,target_size=None):\n",
    "    slide = openslide.OpenSlide(wsi_path)\n",
    "    mag = get_wsi_magnification(slide)\n",
    "    print(f\"Magnification: {mag}x\")\n",
    "    scale_factor = mag / 5.0\n",
    "    print(f\"Scale factor: {scale_factor}\")\n",
    "    # print original dimensions of the WSI \n",
    "    print(f\"Original dimensions: {slide.dimensions}\")\n",
    "    # Calculate level to read from for downsampling to 5x\n",
    "    level = slide.get_best_level_for_downsample(scale_factor)\n",
    "    downsample = slide.level_downsamples[level]\n",
    "    print(f\"Using scale factor: {scale_factor} the best level {level} with downsample factor {downsample}\")\n",
    "    # Downsample to 5x\n",
    "    downsampled_width = int(slide.level_dimensions[0][0] / scale_factor)\n",
    "    downsampled_height = int(slide.level_dimensions[0][1] / scale_factor)\n",
    "    print(f\"Downsampled dimensions: {downsampled_width} x {downsampled_height}\")\n",
    "    region = slide.read_region((0, 0), level, slide.level_dimensions[level])\n",
    "    # print the region size after downsample\n",
    "    print(f\"Downsampled region dimensions using read region: {region.size}\")\n",
    "    downsampled_img = region.resize((downsampled_width, downsampled_height), Image.LANCZOS)\n",
    "    print(f\"Downsampled dimensions using resize: {downsampled_img.size}\")\n",
    "    \n",
    "    # Resize the image to the exact target size if necessary\n",
    "    if target_size:\n",
    "        resized_img = downsampled_img.resize(target_size, Image.LANCZOS)\n",
    "    \n",
    "    # Save the downsampled and resized image with the label in the filename\n",
    "    # output_path = os.path.join(output_dir, f\"{os.path.basename(wsi_path)[:12]}_{label}.png\")\n",
    "    # if not os.path.exists(os.path.dirname(output_path)):\n",
    "    #     os.makedirs(os.path.dirname(output_path))\n",
    "    # downsampled_img.save(output_path)\n",
    "    # print(f\"Saved downsampled and resized WSI to {output_path}\")\n",
    "\n",
    "# Process all WSI images in the input directory\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    for wsi_file in files:\n",
    "        if wsi_file.endswith('.svs') or wsi_file.endswith('.tiff'):\n",
    "            wsi_path = os.path.join(root, wsi_file)\n",
    "            print(f\"Processing WSI: {wsi_file}\")\n",
    "            downsample_and_resize_wsi(wsi_path, output_dir, label, target_size)\n",
    "\n",
    "print(\"Finished DownSampling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DownSampling Using CLAM approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dimensions: (95615, 74462) of wsi TCGA-3L-AA1B_nonMSIH\n",
      "Downsampled image dimensions: (23903, 18615)\n",
      "Cropped image dimensions: (23903, 16991)\n",
      "Downsampled cropped image dimensions old method: (23903, 17151)\n",
      "Original dimensions: (101680, 36748) of wsi TCGA-A6-2671_nonMSIH\n",
      "Downsampled image dimensions: (25420, 9187)\n",
      "Cropped image dimensions: (25041, 8394)\n",
      "Downsampled cropped image dimensions old method: (25046, 8542)\n",
      "Original dimensions: (157316, 21227) of wsi TCGA-A6-2675_nonMSIH\n",
      "Downsampled image dimensions: (39329, 5306)\n",
      "Cropped image dimensions: (26302, 2688)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 77\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# print original dimensions of the WSI\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal dimensions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mslide\u001b[38;5;241m.\u001b[39mdimensions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of wsi \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mslide_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 77\u001b[0m \u001b[43msave_downsampled_cropped_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWSI_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslide_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 65\u001b[0m, in \u001b[0;36msave_downsampled_cropped_image\u001b[1;34m(WSI_object, slide_id, save_dir)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDownsampled image dimensions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdownsampled_image\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     64\u001b[0m crop_downsample_image(downsampled_image,cropped_save_path)\n\u001b[1;32m---> 65\u001b[0m \u001b[43mcrop_downsample_image_old\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownsampled_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcropped_save_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 13\u001b[0m, in \u001b[0;36mcrop_downsample_image_old\u001b[1;34m(image, output_path)\u001b[0m\n\u001b[0;32m     11\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Calculate the Laplacian variance of the grayscale image\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m variance \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLaplacian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCV_64F\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# If variance is too low, indicating a uniform region, adjust the threshold\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m variance \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m50\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\datai\\anaconda3\\envs\\tcga\\Lib\\site-packages\\numpy\\core\\_methods.py:187\u001b[0m, in \u001b[0;36m_var\u001b[1;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;66;03m# Most general case; includes handling object arrays containing imaginary\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# numbers and complex types with non-native byteorder\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     x \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39mmultiply(x, um\u001b[38;5;241m.\u001b[39mconjugate(x), out\u001b[38;5;241m=\u001b[39mx)\u001b[38;5;241m.\u001b[39mreal\n\u001b[1;32m--> 187\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m# Compute degrees of freedom and make sure it is not negative.\u001b[39;00m\n\u001b[0;32m    190\u001b[0m rcount \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39mmaximum(rcount \u001b[38;5;241m-\u001b[39m ddof, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_wsi_magnification(slide):\n",
    "    try:\n",
    "        magnification = slide.properties[openslide.PROPERTY_NAME_OBJECTIVE_POWER]\n",
    "        return float(magnification)\n",
    "    except KeyError:\n",
    "        raise ValueError(\"Magnification information not available in the WSI properties.\")\n",
    "\n",
    "def crop_downsample_image_old(image, output_path):\n",
    "    image = np.array(image)\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate the Laplacian variance of the grayscale image\n",
    "    variance = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "    # If variance is too low, indicating a uniform region, adjust the threshold\n",
    "    if variance < 50:\n",
    "        _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "    else:\n",
    "        # Apply a binary threshold to get the detailed regions\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        _, thresh = cv2.threshold(blurred, 150, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Sort contours by area (descending) to get top 10 largest contours\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
    "    # Initialize an empty mask to draw the contours\n",
    "    mask = np.zeros_like(gray)\n",
    "    # Draw the top 10 contours on the mask\n",
    "    cv2.drawContours(mask, contours, -1, 255, thickness=cv2.FILLED)\n",
    "    # Find bounding box coordinates of the masked area\n",
    "    x, y, w, h = cv2.boundingRect(mask)\n",
    "    # Crop the image to the bounding box\n",
    "    cropped_image = image[y:y+h, x:x+w]\n",
    "    cropped_image = Image.fromarray(cropped_image)\n",
    "    # Save the cropped image\n",
    "    # cropped_image.save(output_path)\n",
    "    print(f'Downsampled cropped image dimensions old method: {cropped_image.size}')\n",
    "\n",
    "def crop_downsample_image(image, output_path):\n",
    "    image = np.array(image)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)  # Adjust threshold for white background\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
    "    mask = np.zeros_like(gray)\n",
    "    cv2.drawContours(mask, contours, -1, 255, thickness=cv2.FILLED)\n",
    "    x, y, w, h = cv2.boundingRect(mask)\n",
    "    cropped_image = image[y:y+h, x:x+w]\n",
    "    cropped_image = Image.fromarray(cropped_image)\n",
    "    # cropped_image.save(output_path)\n",
    "    print(f'Cropped image dimensions: {cropped_image.size}')\n",
    "\n",
    "def save_downsampled_cropped_image(WSI_object, slide_id, save_dir):\n",
    "    mag = get_wsi_magnification(WSI_object.getOpenSlide())\n",
    "    scale_factor = mag / 5.0\n",
    "    wsi = WSI_object.getOpenSlide()\n",
    "    best_level = wsi.get_best_level_for_downsample(scale_factor)\n",
    "    downsampled_image = WSI_object.getOpenSlide().read_region((0, 0), best_level, WSI_object.level_dim[best_level])\n",
    "    downsampled_image = downsampled_image.convert(\"RGB\")\n",
    "    # downsampled_image_path = os.path.join(save_dir, slide_id + '_downsampled.png')\n",
    "    # downsampled_image.save(downsampled_image_path)\n",
    "    # Crop the downsampled image\n",
    "    cropped_save_path = os.path.join(save_dir, slide_id + '.png')\n",
    "    print(f'Downsampled image dimensions: {downsampled_image.size}')\n",
    "    crop_downsample_image(downsampled_image,cropped_save_path)\n",
    "    crop_downsample_image_old(downsampled_image,cropped_save_path)\n",
    "\n",
    "# Process all WSI images in the input directory\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    for wsi_file in files:\n",
    "        if wsi_file.endswith('.svs') or wsi_file.endswith('.tiff'):\n",
    "            wsi_path = os.path.join(root, wsi_file)\n",
    "            slide_id = os.path.basename(wsi_path).split('.')[0]\n",
    "            slide = openslide.OpenSlide(wsi_path)\n",
    "            WSI_object = WholeSlideImage(wsi_path)\n",
    "            # print original dimensions of the WSI\n",
    "            print(f\"Original dimensions: {slide.dimensions} of wsi {slide_id}\")\n",
    "            save_downsampled_cropped_image(WSI_object, slide_id, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for verification of already downsampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import openslide\n",
    "from PIL import Image\n",
    "\n",
    "def get_wsi_metadata(slide, slide_id):\n",
    "    \"\"\"\n",
    "    Extract metadata from a slide object, including magnification, scale factors, and downsample level.\n",
    "    Parameters:\n",
    "        slide (OpenSlide): The loaded WSI slide.\n",
    "        slide_id (str): The identifier of the slide (file name without extension).\n",
    "    Returns:\n",
    "        dict: Metadata including slide_id, dimensions, magnification, mpp, scale factors, and downsample level.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        width, height = slide.dimensions\n",
    "        objective_power = slide.properties.get('openslide.objective-power', 'Unknown')\n",
    "        mpp_x = slide.properties.get('openslide.mpp-x', 'Unknown')\n",
    "        mpp_y = slide.properties.get('openslide.mpp-y', 'Unknown')\n",
    "        scale_factor = slide.properties.get('aperio.AppMag', 'Unknown')\n",
    "\n",
    "        # Safely calculate scale_factor2 and downsample_level\n",
    "        scale_factor2 = float(objective_power) / 5 if objective_power != 'Unknown' else None\n",
    "        downsample_level = slide.get_best_level_for_downsample(scale_factor2) if scale_factor2 else None\n",
    "\n",
    "        # Prepare metadata dictionary\n",
    "        metadata = {\n",
    "            \"slide_id\": slide_id,\n",
    "            \"width\": width,\n",
    "            \"height\": height,\n",
    "            \"magnification_power\": float(objective_power) if objective_power != 'Unknown' else None,\n",
    "            \"mpp_x\": round(float(mpp_x), 3) if mpp_x != 'Unknown' else None,\n",
    "            \"mpp_y\": round(float(mpp_y), 3) if mpp_y != 'Unknown' else None,\n",
    "            \"scale_factor\": scale_factor,\n",
    "            \"scale_factor2\": scale_factor2,\n",
    "            \"downsample_level\": downsample_level\n",
    "        }\n",
    "        return metadata\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving metadata for slide {slide_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "def calculate_cropped_downsampling(original_width, cropped_width, level):\n",
    "    org_downsample_level = original_width / cropped_width\n",
    "    org_level_downsample = original_width / level\n",
    "    return org_downsample_level, org_level_downsample\n",
    "\n",
    "\n",
    "def save_metadata_to_csv(input_dir, png_dir, output_csv):\n",
    "    \"\"\"\n",
    "    Process all slides in the input directory, calculate metadata, and update with downsampled image dimensions.\n",
    "    Parameters:\n",
    "        input_dir (str): Directory containing .svs files.\n",
    "        png_dir (str): Directory containing the downsampled PNG images.\n",
    "        output_csv (str): Path to save the metadata CSV file.\n",
    "    \"\"\"\n",
    "    fieldnames = [\n",
    "        \"slide_id\", \"width\", \"height\", \"magnification_power\", \"mpp_x\", \"mpp_y\", \"scale_factor\", \"scale_factor2\", \"downsample_level\", \"downsampled_width\", \"downsampled_height\", \"calculated_downsample_factor\", \"calculated_downsample_level\"\n",
    "    ]\n",
    "    results = []\n",
    "\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for wsi_file in files:\n",
    "            if wsi_file.endswith('.svs') or wsi_file.endswith('.tiff'):\n",
    "                wsi_path = os.path.join(root, wsi_file)\n",
    "                slide_id = os.path.splitext(wsi_file)[0]\n",
    "\n",
    "                try:\n",
    "                    slide = openslide.OpenSlide(wsi_path)\n",
    "                    metadata = get_wsi_metadata(slide, slide_id)\n",
    "\n",
    "                    if metadata:\n",
    "                        # Add downsampled dimensions\n",
    "                        png_path = os.path.join(png_dir, f\"{slide_id}.png\")\n",
    "                        if os.path.exists(png_path):\n",
    "                            with Image.open(png_path) as img:\n",
    "                                metadata[\"downsampled_width\"], metadata[\"downsampled_height\"] = img.size\n",
    "\n",
    "                                # Calculate cropped downsampling factor and level\n",
    "                                org_downsample_level, org_level_downsample = calculate_cropped_downsampling(\n",
    "                                    metadata[\"width\"], metadata[\"height\"],metadata[\"downsample_level\"] , img.size[0], img.size[1]\n",
    "                                )\n",
    "                                metadata[\"org_downsample_level\"] = org_downsample_level\n",
    "                                metadata[\"org_level_downsample\"] = org_level_downsample\n",
    "                        else:\n",
    "                            metadata[\"downsampled_width\"] = \"Not Found\"\n",
    "                            metadata[\"downsampled_height\"] = \"Not Found\"\n",
    "                            metadata[\"calculated_downsample_factor\"] = \"Not Found\"\n",
    "                            metadata[\"calculated_downsample_level\"] = \"Not Found\"\n",
    "\n",
    "                        results.append(metadata)\n",
    "                        print(f\"Processed slide: {slide_id}\")\n",
    "                        print(metadata)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing slide {slide_id}: {e}\")\n",
    "    \n",
    "    # Write results to CSV\n",
    "    # with open(output_csv, mode='w', newline='') as csvfile:\n",
    "    #     writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    #     writer.writeheader()\n",
    "    #     writer.writerows(results)\n",
    "\n",
    "    print(f\"Metadata saved to {output_csv}\")\n",
    "\n",
    "# Example usage\n",
    "input_dir = r'E:\\\\KSA Project\\\\dataset\\\\svs_files'  # Replace with the actual path to your slides\n",
    "png_dir = r'E:\\\\KSA Project\\\\dataset\\\\cropped_data'  # Directory containing downsampled PNG images\n",
    "output_csv = r'E:\\\\KSA Project\\\\dataset\\\\svs_metadata2.csv'  # Path to save the metadata CSV\n",
    "save_metadata_to_csv(input_dir, png_dir, output_csv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcga",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
