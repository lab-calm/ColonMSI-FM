{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection of Tissue Region Top patches and their Caption Ranking using Conch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from typing import List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "# set max PIL image size.02\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import KMeans\n",
    "from torchvision import transforms\n",
    "from conch.open_clip_custom import create_model_from_pretrained, get_tokenizer, tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file of WSI\n",
    "wsi_df = pd.read_csv(r\"E:\\KSA Project\\dataset\\paip_data\\labels\\paip_reviewed_slides.csv\")\n",
    "# set the WSI_Id column and select first 10 values and convert it into list\n",
    "wsi_id_list = wsi_df[\"WSI_Id\"].values[:4].tolist()\n",
    "feature_dir = r\"E:\\KSA Project\\dataset\\paip_data\\CONCH_FiveCrop_Features\"  # Feature directory\n",
    "image_dir = r\"E:\\KSA Project\\dataset\\paip_data\\patches\"  # Patch images directory\n",
    "output_dir = r\"E:\\KSA Project\\dataset\\paip_data\\output\\prompts11_Reviewed_Patches\"  # CSV save path\n",
    "# create output directory if not exists\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the minimum and maximum no of patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(wsi_df[\"label\"].value_counts())\n",
    "# # Define the path\n",
    "# path = image_dir\n",
    "# # Get all the directories in the specified path\n",
    "# directories = [os.path.join(path, d) for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "# # Initialize a list to store file counts\n",
    "# file_counts = []\n",
    "# # Loop through each directory and count the files\n",
    "# for dir in directories:\n",
    "#     file_count = len([f for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f))])\n",
    "#     file_counts.append(file_count)\n",
    "# print(f\"Minimum File Count: {min(file_counts)}\")\n",
    "# print(f\"Maximum File Count: {max(file_counts)}\")\n",
    "# print(f\"Average File Count: { sum(file_counts) / len(file_counts):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer for captions\n",
    "model, preprocess = create_model_from_pretrained(\n",
    "    model_cfg='conch_ViT-B-16', checkpoint_path='./checkpoints/pytorch_model.bin'\n",
    ")\n",
    "_ = model.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "tokenizer = get_tokenizer()\n",
    "prompts = [\n",
    "    \"Adipose\",\n",
    "    \"Debris\",\n",
    "    \"Lymphocytes\",\n",
    "    \"Plasma cells\",\n",
    "    \"Mucin\",\n",
    "    \"Smooth Muscle\",\n",
    "    \"Normal Mucosa\",\n",
    "    \"Stroma\",\n",
    "    \"Connective tissue\",\n",
    "    \"Adenoma\",\n",
    "    \"Tumor\"\n",
    "]\n",
    "\n",
    "# Encode prompts properly\n",
    "with torch.inference_mode():\n",
    "    tokenized_prompts = tokenize(texts=prompts, tokenizer=tokenizer).to(device)\n",
    "    text_embeddings = model.encode_text(tokenized_prompts)  # Ensure it gives [7, 512] shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TopPatches Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_top_patches_from_clusters(patch_array, patch_filenames, num_clusters=2, num_patches_per_cluster=1):\n",
    "    \"\"\"\n",
    "    Performs clustering and selects top representative patches from **both clusters**.\n",
    "    Args:\n",
    "        patch_array (np.array): Array of patch feature vectors.\n",
    "        patch_filenames (list): List of patch filenames corresponding to the feature vectors.\n",
    "        num_clusters (int): Number of clusters.\n",
    "        num_patches_per_cluster (int): Number of patches to pick **per cluster**.\n",
    "\n",
    "    Returns:\n",
    "        selected_patch_files (list): Filenames of selected patches.\n",
    "        selected_patch_features (list): Feature vectors of selected patches.\n",
    "    \"\"\"\n",
    "    # Perform clustering\n",
    "    clustering_model = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    clustering_model.fit(patch_array)\n",
    "    cluster_labels = clustering_model.labels_\n",
    "    cluster_centroids = clustering_model.cluster_centers_\n",
    "\n",
    "    selected_patch_files = []\n",
    "    selected_patch_features = []\n",
    "\n",
    "    for cluster_idx in range(num_clusters):\n",
    "        cluster_indices = np.where(cluster_labels == cluster_idx)[0]\n",
    "        if len(cluster_indices) == 0:\n",
    "            continue  # Skip empty clusters\n",
    "\n",
    "        # Compute distances from centroid\n",
    "        cluster_patches = patch_array[cluster_indices]\n",
    "        cluster_patch_files = [patch_filenames[i] for i in cluster_indices]\n",
    "        distances = cdist(cluster_patches, [cluster_centroids[cluster_idx]], metric='euclidean').flatten()\n",
    "\n",
    "        # Sort by proximity to centroid\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        selected_indices = sorted_indices[:num_patches_per_cluster]  # Pick **top patches** per cluster\n",
    "\n",
    "        # Store selected patch filenames & features\n",
    "        selected_patch_files.extend([cluster_patch_files[i] for i in selected_indices])\n",
    "        selected_patch_features.extend([patch_array[cluster_indices[i]] for i in selected_indices])\n",
    "\n",
    "    return selected_patch_files, selected_patch_features\n",
    "\n",
    "\n",
    "def display_top_patches_with_captions_and_save_csv(\n",
    "    wsi_id_list, feature_dir, image_dir, wsi_df, output_dir, num_clusters=2\n",
    "):\n",
    "    \"\"\"\n",
    "    Displays the top selected patches for given WSIs with ranked caption annotations.\n",
    "    Saves the results in a CSV file.\n",
    "\n",
    "    Args:\n",
    "        wsi_id_list (list): List of WSI Identifiers.\n",
    "        feature_dir (str): Directory containing feature .pt files.\n",
    "        image_dir (str): Directory containing patch images.\n",
    "        wsi_df (pd.DataFrame): DataFrame containing WSI_Id and corresponding label.\n",
    "        output_dir (str): Path to save the results.\n",
    "        num_clusters (int): Number of clusters.\n",
    "\n",
    "    Returns:\n",
    "        None (Displays images and saves CSV)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for wsi_id in wsi_id_list:\n",
    "        print(f\"Processing WSI: {wsi_id}\")\n",
    "\n",
    "        # Load WSI label\n",
    "        wsi_label = wsi_df.loc[wsi_df[\"WSI_Id\"] == wsi_id, \"label\"].values\n",
    "        if len(wsi_label) > 0:\n",
    "            wsi_label = wsi_label[0]\n",
    "        else:\n",
    "            print(f\"⚠️ No label found for {wsi_id}, skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Adjust number of selected patches based on label\n",
    "        if wsi_label == \"MSIH\":\n",
    "            num_patches_per_cluster = 3  # Pick more patches for MSI\n",
    "        else:\n",
    "            num_patches_per_cluster = 3  # Pick fewer patches for nonMSI\n",
    "\n",
    "        # Load patch feature vectors\n",
    "        feature_dir_path = os.path.join(feature_dir, wsi_id)\n",
    "        feature_files = [f for f in os.listdir(feature_dir_path) if f.endswith('.pt')]\n",
    "        patch_features = []\n",
    "        for feature_file in feature_files:\n",
    "            feature_path = os.path.join(feature_dir_path, feature_file)\n",
    "            feature_data = torch.load(feature_path)\n",
    "            if feature_data.ndim == 2 and feature_data.shape[0] == 5:  # FiveCrop averaging\n",
    "                feature_data = feature_data.mean(dim=0)\n",
    "            patch_features.append(feature_data)\n",
    "\n",
    "        patch_array = torch.stack(patch_features).cpu().numpy()\n",
    "        if patch_array.ndim == 3:\n",
    "            patch_array = patch_array.reshape(patch_array.shape[0], -1)\n",
    "\n",
    "        # Get patch filenames\n",
    "        wsi_image_dir = os.path.join(image_dir, wsi_id)\n",
    "        patch_filenames = sorted([f for f in os.listdir(wsi_image_dir) if f.endswith('.png')])\n",
    "\n",
    "        if len(patch_filenames) != len(patch_array):\n",
    "            print(f\"⚠️ Mismatch: {len(patch_filenames)} images vs {len(patch_array)} feature vectors. Skipping WSI.\")\n",
    "            continue\n",
    "\n",
    "        # Select patches from **both clusters**\n",
    "        selected_patch_files, selected_patch_features = select_top_patches_from_clusters(\n",
    "            patch_array, patch_filenames, num_clusters, num_patches_per_cluster\n",
    "        )\n",
    "\n",
    "        # Compute captions and save results\n",
    "        ranked_captions = {}\n",
    "        for patch_file, patch_feature in zip(selected_patch_files, selected_patch_features):\n",
    "            patch_tensor = torch.tensor(patch_feature).unsqueeze(0).to(device)  # Convert feature to tensor\n",
    "            with torch.inference_mode():\n",
    "                sim_scores = (patch_tensor @ text_embeddings.T).squeeze(0)  # Compute similarity with prompts\n",
    "\n",
    "            ranked_scores, ranked_idx = torch.sort(sim_scores, descending=True)\n",
    "            best_caption = prompts[ranked_idx[0]]  # Best-matching caption\n",
    "            ranked_captions[patch_file] = best_caption\n",
    "\n",
    "            # Store results in CSV format\n",
    "            row = [wsi_id, wsi_label, patch_file] + [sim_scores[idx].item() for idx in range(len(prompts))] + [\n",
    "                best_caption\n",
    "            ]\n",
    "            results.append(row)\n",
    "        # continue\n",
    "        # Display selected patches with captions\n",
    "        total_patches = len(selected_patch_files)\n",
    "        fig, axes = plt.subplots(2, num_patches_per_cluster, figsize=(15, 7))  # 2-row grid layout\n",
    "        plt.subplots_adjust(hspace=0.3)  # Adjust spacing between rows\n",
    "\n",
    "        for i, patch_file in enumerate(selected_patch_files):\n",
    "            row = 0 if i < num_patches_per_cluster else 1  # First 4 patches in row 1, next 4 in row 2\n",
    "            col = i % num_patches_per_cluster  # 4 columns\n",
    "\n",
    "            patch_path = os.path.join(image_dir, wsi_id, patch_file)\n",
    "            img = Image.open(patch_path)\n",
    "\n",
    "            # Display image\n",
    "            axes[row, col].imshow(img)\n",
    "            axes[row, col].axis('off')\n",
    "\n",
    "            # Add **Patch Name** on Top\n",
    "            axes[row, col].set_title(patch_file, fontsize=6, color='black', pad=10)\n",
    "\n",
    "            # Add **Best Caption** Below (Truncate long captions)\n",
    "            caption = ranked_captions.get(patch_file, \"No Caption\")\n",
    "            truncated_caption = (caption[:50] + \"...\") if len(caption) > 50 else caption  # Shorten long captions\n",
    "            axes[row, col].text(0.5, -0.1, truncated_caption, ha='center', va='top', fontsize=8, color='blue', wrap=True,\n",
    "                                transform=axes[row, col].transAxes)\n",
    "\n",
    "        plt.suptitle(f\"WSI: {wsi_id} | Top {num_patches_per_cluster} Patches Per Cluster\", fontsize=10, fontweight='bold')\n",
    "\n",
    "        # Save as high-quality PNG\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        save_path = os.path.join(output_dir, f\"{wsi_id}.png\")\n",
    "        plt.savefig(save_path, format='png', dpi=300, bbox_inches='tight')\n",
    "        print(f\"✅ Saved visualization: {save_path}\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    # Save the results in a CSV file\n",
    "    columns = [\"WSI_Id\", \"Label\", \"Patch_ID\"] + [f\"Prompt_{i+1}\" for i in range(len(prompts))] + [\"Best_Caption\"]\n",
    "    df = pd.DataFrame(results, columns=columns)\n",
    "    output_csv = os.path.join(output_dir, \"top_patch_results_top1_2cluster.csv\")\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"✅ Results saved to: {output_csv}\")\n",
    "\n",
    "# Display top 2 patches per cluster for each WSI with captions\n",
    "display_top_patches_with_captions_and_save_csv(wsi_id_list, feature_dir, image_dir, wsi_df, output_dir, num_clusters=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select topPatches and Plot FiveCrops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing WSI: training_data_01_MSIH\n",
      "Feature dir not found for training_data_01_MSIH, skipping.\n",
      "Processing WSI: training_data_05_MSIH\n",
      "All results saved => E:\\KSA Project\\dataset\\paip_data\\output\\prompts11_Reviewed_Patches\\top_patch_fivecrop_results.csv\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# 1) CLUSTERING HELPER (unchanged, just returns top patches)\n",
    "# =======================================================================\n",
    "def select_top_patches_from_clusters(\n",
    "    patch_array,       # shape [N, D], one vector per patch\n",
    "    patch_filenames,\n",
    "    num_clusters=2,\n",
    "    num_patches_per_cluster=1\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs clustering and selects top representative patches from each cluster.\n",
    "    By default, picks the top 1 (closest to centroid) per cluster.\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    kmeans.fit(patch_array)\n",
    "    cluster_labels = kmeans.labels_\n",
    "    centroids = kmeans.cluster_centers_\n",
    "\n",
    "    selected_patch_files = []\n",
    "    selected_patch_indices = []\n",
    "\n",
    "    for cluster_idx in range(num_clusters):\n",
    "        cluster_indices = np.where(cluster_labels == cluster_idx)[0]\n",
    "        if len(cluster_indices) == 0:\n",
    "            continue\n",
    "\n",
    "        # Distances of patches in this cluster to the centroid\n",
    "        cluster_vectors = patch_array[cluster_indices]\n",
    "        distances = cdist(cluster_vectors, [centroids[cluster_idx]], metric='euclidean').flatten()\n",
    "\n",
    "        # Sort patches by distance, pick top N\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        top_indices = sorted_indices[:num_patches_per_cluster]\n",
    "\n",
    "        for ti in top_indices:\n",
    "            patch_global_idx = cluster_indices[ti]\n",
    "            selected_patch_files.append(patch_filenames[patch_global_idx])\n",
    "            selected_patch_indices.append(patch_global_idx)\n",
    "\n",
    "    return selected_patch_files, selected_patch_indices, cluster_labels\n",
    "\n",
    "# =======================================================================\n",
    "# 2) MAIN: AVERAGE FOR CLUSTERING, BUT STILL SHOW FIVE-CROP SUBFEATS\n",
    "# =======================================================================\n",
    "def display_top_patches_with_captions_and_save_csv(\n",
    "    wsi_id_list,\n",
    "    feature_dir,\n",
    "    image_dir,\n",
    "    wsi_df,\n",
    "    output_dir,\n",
    "    num_clusters=2\n",
    "):\n",
    "    \"\"\"\n",
    "    For each WSI:\n",
    "      - Load five-crop features (each patch is [5, D]).\n",
    "      - Average them to [D] for K-Means clustering.\n",
    "      - Pick the top patch(es) per cluster.\n",
    "      - For each selected patch, retrieve the original five-crop sub-features\n",
    "        to generate sub-crop captions & show them side by side.\n",
    "      - Save results to CSV.\n",
    "      - Use a flexible subplot that accommodates any (num_clusters × topPatches).\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    results = []\n",
    "\n",
    "    # If your five-crop was extracted at size=224:\n",
    "    five_crop_transform = transforms.FiveCrop(size=224)\n",
    "\n",
    "    for wsi_id in wsi_id_list:\n",
    "        print(f\"Processing WSI: {wsi_id}\")\n",
    "\n",
    "        # --- Lookup label (optional) ---\n",
    "        row = wsi_df.loc[wsi_df[\"WSI_Id\"] == wsi_id]\n",
    "        if len(row) < 1:\n",
    "            print(f\"⚠️ No label found for WSI: {wsi_id}, skipping...\")\n",
    "            continue\n",
    "        wsi_label = row.iloc[0][\"label\"]\n",
    "\n",
    "        # Adjust how many top patches you want\n",
    "        if wsi_label == \"MSIH\":\n",
    "            num_patches_per_cluster = 1\n",
    "        else:\n",
    "            num_patches_per_cluster = 1\n",
    "\n",
    "        # -------------------------------------------------------------------\n",
    "        # A) LOAD FIVE-CROP FEATURES\n",
    "        # -------------------------------------------------------------------\n",
    "        feature_dir_path = os.path.join(feature_dir, wsi_id)\n",
    "        if not os.path.isdir(feature_dir_path):\n",
    "            print(f\"Feature dir not found for {wsi_id}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        feature_files = [f for f in os.listdir(feature_dir_path) if f.endswith('.pt')]\n",
    "        patch_filenames = []\n",
    "        patch_features_5crop_list = []  # each entry is shape [5, D]\n",
    "\n",
    "        for ffile in feature_files:\n",
    "            path = os.path.join(feature_dir_path, ffile)\n",
    "            feat_5crops = torch.load(path)  # shape [5, D]\n",
    "            patch_features_5crop_list.append(feat_5crops)\n",
    "            patch_filenames.append(ffile.replace('.pt', '.png'))\n",
    "\n",
    "        if len(patch_features_5crop_list) == 0:\n",
    "            print(f\"No patch features for {wsi_id}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # -------------------------------------------------------------------\n",
    "        # B) AVERAGE sub-crops to get [D] per patch (for K-Means)\n",
    "        # -------------------------------------------------------------------\n",
    "        # We keep the original 5×D in patch_features_5crop_list for later,\n",
    "        # but build a second array for clustering\n",
    "        all_avg = []\n",
    "        for pf in patch_features_5crop_list:\n",
    "            avg_feat = pf.mean(dim=0)  # shape [D]\n",
    "            all_avg.append(avg_feat.cpu().numpy())\n",
    "        patch_array_for_clustering = np.stack(all_avg, axis=0)  # shape [N, D]\n",
    "\n",
    "        # -------------------------------------------------------------------\n",
    "        # C) K-Means, pick top patches\n",
    "        # -------------------------------------------------------------------\n",
    "        wsi_image_dir = os.path.join(image_dir, wsi_id)\n",
    "        if not os.path.isdir(wsi_image_dir):\n",
    "            print(f\"Image dir not found for {wsi_id}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        selected_files, selected_indices, cluster_labels = select_top_patches_from_clusters(\n",
    "            patch_array_for_clustering,\n",
    "            patch_filenames,\n",
    "            num_clusters=num_clusters,\n",
    "            num_patches_per_cluster=num_patches_per_cluster\n",
    "        )\n",
    "\n",
    "        # We'll gather data for CSV here\n",
    "        columns = ([\"WSI_Id\", \"Label\", \"Patch_ID\", \"Crop_Index\"] +\n",
    "                   [f\"Prompt_{i+1}\" for i in range(len(prompts))] +\n",
    "                   [\"Best_Caption\"])\n",
    "        cluster_rows = []\n",
    "\n",
    "        # -------------------------------------------------------------------\n",
    "        # D) Flexible subplot layout\n",
    "        #    Each selected patch => one row\n",
    "        #    6 columns => col0 for original patch, col1..5 for sub-crops\n",
    "        # -------------------------------------------------------------------\n",
    "        n_rows = len(selected_files)\n",
    "        n_cols = 6\n",
    "\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(3.5*n_cols, 3*n_rows))\n",
    "        # If there's only 1 row, axes might be 1D => make it 2D for uniform indexing\n",
    "        if n_rows == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for row_idx, (patch_fname, patch_index) in enumerate(zip(selected_files, selected_indices)):\n",
    "\n",
    "            # The original 5×D sub-features\n",
    "            five_crop_feats = patch_features_5crop_list[patch_index]\n",
    "\n",
    "            # Load the original patch image\n",
    "            patch_path = os.path.join(wsi_image_dir, patch_fname)\n",
    "            try:\n",
    "                original_img = Image.open(patch_path).convert(\"RGB\")\n",
    "            except:\n",
    "                print(f\"Could not open {patch_path}, skipping row.\")\n",
    "                continue\n",
    "\n",
    "            # Show original in col0\n",
    "            axes[row_idx][0].imshow(original_img)\n",
    "            axes[row_idx][0].axis('off')\n",
    "            axes[row_idx][0].set_title(f\"ClusterRow {row_idx}\\n{patch_fname}\", fontsize=7, color='red')\n",
    "\n",
    "            # Generate sub-crops exactly as done during feature extraction\n",
    "            subcrop_imgs = five_crop_transform(original_img)  # tuple of 5 PIL images\n",
    "\n",
    "            # For each sub-crop, do similarity => caption\n",
    "            for c_idx in range(5):\n",
    "                sub_img = subcrop_imgs[c_idx]\n",
    "                sub_feat = five_crop_feats[c_idx].unsqueeze(0).to(device)  # shape [1, D]\n",
    "\n",
    "                # Compute similarity\n",
    "                with torch.inference_mode():\n",
    "                    sim_scores = (sub_feat @ text_embeddings.T).squeeze(0)\n",
    "                ranked_scores, ranked_idx = torch.sort(sim_scores, descending=True)\n",
    "                best_prompt_idx = ranked_idx[0].item()\n",
    "                best_caption = prompts[best_prompt_idx]\n",
    "\n",
    "                # Show sub-crop in col c_idx+1\n",
    "                ax = axes[row_idx][c_idx + 1]\n",
    "                ax.imshow(sub_img)\n",
    "                ax.axis('off')\n",
    "                # Title with crop index + truncated caption\n",
    "                short_caption = best_caption[:35] + \"...\" if len(best_caption) > 35 else best_caption\n",
    "                ax.set_title(\n",
    "                    f\"Crop {c_idx}, Prompt {best_prompt_idx+1}\\n{short_caption}\",\n",
    "                    fontsize=7, color='blue'\n",
    "                )\n",
    "\n",
    "                # Save row for CSV\n",
    "                row_data = [\n",
    "                    wsi_id,                      # WSI_Id\n",
    "                    wsi_label,                   # Label\n",
    "                    patch_fname,                 # Patch_ID\n",
    "                    c_idx                        # Crop index\n",
    "                ]\n",
    "                # Add each prompt's sim score\n",
    "                row_data.extend(sim_scores.cpu().tolist())\n",
    "                # Add best caption\n",
    "                row_data.append(best_caption)\n",
    "                cluster_rows.append(row_data)\n",
    "\n",
    "        plt.suptitle(f\"{wsi_id}: {num_clusters} cluster(s), top{num_patches_per_cluster} patch(es) each\", \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        # Save figure\n",
    "        out_fig = os.path.join(output_dir, f\"{wsi_id}_topPatches.png\")\n",
    "        plt.savefig(out_fig, format='png', dpi=500, bbox_inches='tight')\n",
    "        # plt.show()\n",
    "        plt.close()\n",
    "        # Convert cluster_rows to DataFrame, store for final CSV\n",
    "        if len(cluster_rows) > 0:\n",
    "            wsi_df_rows = pd.DataFrame(cluster_rows, columns=columns)\n",
    "            results.append(wsi_df_rows)\n",
    "\n",
    "    # =====================================================================\n",
    "    # E) SAVE ALL WSIs' RESULTS TO CSV\n",
    "    # =====================================================================\n",
    "    if len(results) == 0:\n",
    "        print(\"No results to save.\")\n",
    "        return\n",
    "\n",
    "    final_df = pd.concat(results, ignore_index=True)\n",
    "    out_csv = os.path.join(output_dir, \"top_patch_fivecrop_results.csv\")\n",
    "    final_df.to_csv(out_csv, index=False)\n",
    "    print(f\"All results saved => {out_csv}\")\n",
    "\n",
    "display_top_patches_with_captions_and_save_csv(\n",
    "    wsi_id_list=wsi_id_list,\n",
    "    feature_dir= feature_dir,\n",
    "    image_dir=  image_dir,\n",
    "    wsi_df= wsi_df,\n",
    "    output_dir= output_dir,\n",
    "    num_clusters=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patches  with Bar chart code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing WSI: training_data_01_MSIH\n",
      "Feature dir not found for training_data_01_MSIH, skipping.\n",
      "Processing WSI: training_data_05_MSIH\n",
      "Processing WSI: training_data_06_MSIH\n",
      "Feature dir not found for training_data_06_MSIH, skipping.\n",
      "Processing WSI: training_data_20_MSIH\n",
      "Feature dir not found for training_data_20_MSIH, skipping.\n",
      "All results saved => E:\\KSA Project\\dataset\\paip_data\\output\\prompts11_Reviewed_Patches\\top_patch_fivecrop_results.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# =======================================================================\n",
    "# 1) CLUSTERING HELPER (unchanged, just returns top patches)\n",
    "# =======================================================================\n",
    "def select_top_patches_from_clusters(\n",
    "    patch_array,       # shape [N, D], one vector per patch\n",
    "    patch_filenames,\n",
    "    num_clusters=2,\n",
    "    num_patches_per_cluster=1\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs clustering and selects top representative patches from each cluster.\n",
    "    By default, picks the top 1 (closest to centroid) per cluster.\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    kmeans.fit(patch_array)\n",
    "    cluster_labels = kmeans.labels_\n",
    "    centroids = kmeans.cluster_centers_\n",
    "\n",
    "    selected_patch_files = []\n",
    "    selected_patch_indices = []\n",
    "\n",
    "    for cluster_idx in range(num_clusters):\n",
    "        cluster_indices = np.where(cluster_labels == cluster_idx)[0]\n",
    "        if len(cluster_indices) == 0:\n",
    "            continue\n",
    "\n",
    "        # Distances of patches in this cluster to the centroid\n",
    "        cluster_vectors = patch_array[cluster_indices]\n",
    "        distances = cdist(cluster_vectors, [centroids[cluster_idx]], metric='euclidean').flatten()\n",
    "\n",
    "        # Sort patches by distance, pick top N\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        top_indices = sorted_indices[:num_patches_per_cluster]\n",
    "\n",
    "        for ti in top_indices:\n",
    "            patch_global_idx = cluster_indices[ti]\n",
    "            selected_patch_files.append(patch_filenames[patch_global_idx])\n",
    "            selected_patch_indices.append(patch_global_idx)\n",
    "\n",
    "    return selected_patch_files, selected_patch_indices, cluster_labels\n",
    "\n",
    "# =======================================================================\n",
    "# 2) MAIN: AVERAGE FOR CLUSTERING, BUT STILL SHOW FIVE-CROP SUBFEATS\n",
    "# =======================================================================\n",
    "def display_top_patches_with_captions_and_save_csv(\n",
    "    wsi_id_list,\n",
    "    feature_dir,\n",
    "    image_dir,\n",
    "    wsi_df,\n",
    "    output_dir,\n",
    "    num_clusters=2\n",
    "):\n",
    "    \"\"\"\n",
    "    For each WSI:\n",
    "      - Load five-crop features (each patch is [5, D]).\n",
    "      - Average them to [D] for K-Means clustering.\n",
    "      - Pick the top patch(es) per cluster.\n",
    "      - For each selected patch, retrieve the original five-crop sub-features\n",
    "        to generate sub-crop captions & show them side by side.\n",
    "      - Make a bar chart (column 6) of each sub-crop's best similarity score.\n",
    "      - Save results to CSV.\n",
    "      - Use a flexible subplot that accommodates any (num_clusters × topPatches).\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    results = []\n",
    "\n",
    "    # If your five-crop was extracted at size=224:\n",
    "    five_crop_transform = transforms.FiveCrop(size=224)\n",
    "\n",
    "    for wsi_id in wsi_id_list:\n",
    "        print(f\"Processing WSI: {wsi_id}\")\n",
    "\n",
    "        # --- Lookup label (optional) ---\n",
    "        row = wsi_df.loc[wsi_df[\"WSI_Id\"] == wsi_id]\n",
    "        if len(row) < 1:\n",
    "            print(f\"⚠️ No label found for WSI: {wsi_id}, skipping...\")\n",
    "            continue\n",
    "        wsi_label = row.iloc[0][\"label\"]\n",
    "\n",
    "        # Adjust how many top patches you want\n",
    "        if wsi_label == \"MSIH\":\n",
    "            num_patches_per_cluster = 1\n",
    "        else:\n",
    "            num_patches_per_cluster = 1\n",
    "        wsi_folder = os.path.join(output_dir, wsi_id)\n",
    "        os.makedirs(wsi_folder, exist_ok=True)\n",
    "        # -------------------------------------------------------------------\n",
    "        # A) LOAD FIVE-CROP FEATURES\n",
    "        # -------------------------------------------------------------------\n",
    "        feature_dir_path = os.path.join(feature_dir, wsi_id)\n",
    "        if not os.path.isdir(feature_dir_path):\n",
    "            print(f\"Feature dir not found for {wsi_id}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        feature_files = [f for f in os.listdir(feature_dir_path) if f.endswith('.pt')]\n",
    "        patch_filenames = []\n",
    "        patch_features_5crop_list = []  # each entry is shape [5, D]\n",
    "\n",
    "        for ffile in feature_files:\n",
    "            path = os.path.join(feature_dir_path, ffile)\n",
    "            feat_5crops = torch.load(path)  # shape [5, D]\n",
    "            patch_features_5crop_list.append(feat_5crops)\n",
    "            patch_filenames.append(ffile.replace('.pt', '.png'))\n",
    "\n",
    "        if len(patch_features_5crop_list) == 0:\n",
    "            print(f\"No patch features for {wsi_id}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # -------------------------------------------------------------------\n",
    "        # B) AVERAGE sub-crops to get [D] per patch (for K-Means)\n",
    "        # -------------------------------------------------------------------\n",
    "        all_avg = []\n",
    "        for pf in patch_features_5crop_list:\n",
    "            avg_feat = pf.mean(dim=0)  # shape [D]\n",
    "            all_avg.append(avg_feat.cpu().numpy())\n",
    "        patch_array_for_clustering = np.stack(all_avg, axis=0)  # shape [N, D]\n",
    "\n",
    "        # -------------------------------------------------------------------\n",
    "        # C) K-Means, pick top patches\n",
    "        # -------------------------------------------------------------------\n",
    "        wsi_image_dir = os.path.join(image_dir, wsi_id)\n",
    "        if not os.path.isdir(wsi_image_dir):\n",
    "            print(f\"Image dir not found for {wsi_id}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        selected_files, selected_indices, cluster_labels = select_top_patches_from_clusters(\n",
    "            patch_array_for_clustering,\n",
    "            patch_filenames,\n",
    "            num_clusters=num_clusters,\n",
    "            num_patches_per_cluster=num_patches_per_cluster\n",
    "        )\n",
    "\n",
    "        # We'll gather data for CSV here\n",
    "        columns = ([\"WSI_Id\", \"Label\", \"Patch_ID\", \"Crop_Index\"] +\n",
    "                   [f\"Prompt_{i+1}\" for i in range(len(prompts))] +\n",
    "                   [\"Best_Caption\"])\n",
    "        cluster_rows = []\n",
    "\n",
    "        # -------------------------------------------------------------------\n",
    "        # D) Flexible subplot layout\n",
    "        #    Each selected patch => one row\n",
    "        #    Now 7 columns => col0 for original patch, col1..5 for sub-crops,\n",
    "        #    col6 is the new bar chart of top similarity scores.\n",
    "        # -------------------------------------------------------------------\n",
    "        n_rows = len(selected_files)\n",
    "        n_cols = 7  # increased from 6 to 7\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(3.5*n_cols, 3*n_rows), gridspec_kw={'wspace': 0.04, 'hspace': 0.09})       \n",
    "        if n_rows == 1:\n",
    "            axes = [axes]\n",
    "        for row_idx, (patch_fname, patch_index) in enumerate(zip(selected_files, selected_indices)):\n",
    "            # Create a subfolder for this patch\n",
    "            patch_stem = patch_fname.replace('.png','')  \n",
    "            patch_folder = os.path.join(wsi_folder, patch_stem)\n",
    "            os.makedirs(patch_folder, exist_ok=True)\n",
    "            # The original 5×D sub-features\n",
    "            five_crop_feats = patch_features_5crop_list[patch_index]\n",
    "\n",
    "            # Load the original patch image\n",
    "            patch_path = os.path.join(wsi_image_dir, patch_fname)\n",
    "            try:\n",
    "                original_img = Image.open(patch_path).convert(\"RGB\")\n",
    "            except:\n",
    "                print(f\"Could not open {patch_path}, skipping row.\")\n",
    "                continue\n",
    "\n",
    "            patch_out_path = os.path.join(patch_folder, patch_fname)\n",
    "            original_img.save(patch_out_path)\n",
    "            # Show original in col0\n",
    "            axes[row_idx][0].imshow(original_img)\n",
    "            axes[row_idx][0].axis('off')\n",
    "            axes[row_idx][0].set_title(f\"{patch_fname}\", fontsize=7, color='red')\n",
    "\n",
    "            # We'll store each sub-crop's best similarity score for the bar chart\n",
    "            best_scores = []\n",
    "            best_captions = []\n",
    "\n",
    "            # Generate sub-crops exactly as done during feature extraction\n",
    "            subcrop_imgs = five_crop_transform(original_img)  # tuple of 5 PIL images\n",
    "\n",
    "            # For each sub-crop, do similarity => caption\n",
    "            for c_idx in range(5):\n",
    "                sub_img = subcrop_imgs[c_idx]\n",
    "                sub_feat = five_crop_feats[c_idx].unsqueeze(0).to(device)  # shape [1, D]\n",
    "                # save sub-crop image\n",
    "                crop_fname = f\"crop{c_idx}.png\"\n",
    "                crop_path = os.path.join(patch_folder, crop_fname)\n",
    "                sub_img.save(crop_path)\n",
    "\n",
    "                # Compute similarity\n",
    "                with torch.inference_mode():\n",
    "                    sim_scores = (sub_feat @ text_embeddings.T).squeeze(0)\n",
    "                ranked_scores, ranked_idx = torch.sort(sim_scores, descending=True)\n",
    "                best_prompt_idx = ranked_idx[0].item()\n",
    "                best_caption = prompts[best_prompt_idx]\n",
    "                best_score = ranked_scores[0].item()  # best sub-crop similarity\n",
    "\n",
    "                # Save best score in a list\n",
    "                best_scores.append(best_score)\n",
    "                best_captions.append(best_caption)\n",
    "                # Show sub-crop in col c_idx+1\n",
    "                ax = axes[row_idx][c_idx + 1]\n",
    "                ax.imshow(sub_img)\n",
    "                ax.axis('off')\n",
    "                # Title with crop index + truncated caption\n",
    "                short_caption = best_caption[:35] + \"...\" if len(best_caption) > 35 else best_caption\n",
    "                ax.set_title(f\"Crop {c_idx}, {short_caption}\",fontsize=7, color='blue')\n",
    "                # Save row for CSV\n",
    "                row_data = [\n",
    "                    wsi_id,                      # WSI_Id\n",
    "                    wsi_label,                   # Label\n",
    "                    patch_fname,                 # Patch_ID\n",
    "                    c_idx                        # Crop index\n",
    "                ]\n",
    "                # Add each prompt's sim score\n",
    "                row_data.extend(sim_scores.cpu().tolist())\n",
    "                # Add best caption\n",
    "                row_data.append(best_caption)\n",
    "                cluster_rows.append(row_data)\n",
    "\n",
    "            # -------------------------------------------------------------------\n",
    "            # E) Bar chart in col6 with the best similarity scores for each crop\n",
    "            # -------------------------------------------------------------------\n",
    "            ax_bar = axes[row_idx][6]\n",
    "            ax_bar.bar(range(5), best_scores)\n",
    "            for i, score in enumerate(best_scores):\n",
    "                # Split best_captions[i] by whitespace\n",
    "                words = best_captions[i].split()\n",
    "                # If there are exactly 2 words, place them on separate lines:\n",
    "                if len(words) == 2:\n",
    "                    text_for_bar = f\"{words[0]}\\n{words[1]}\"\n",
    "                else:\n",
    "                    text_for_bar = best_captions[i]\n",
    "                ax_bar.text(i, score,text_for_bar, ha='center', va='bottom', fontsize=6)\n",
    "            ax_bar.set_xticks(range(5))\n",
    "            ax_bar.set_xticklabels(best_captions, fontsize=7, rotation=45)\n",
    "            ax_bar.set_xticklabels([f\"Crop{i}\" for i in range(5)], fontsize=7, rotation=0)\n",
    "            ax_bar.set_ylim([0, max(best_scores)*1.1 if best_scores else 1])\n",
    "            ax_bar.tick_params(axis='y', labelsize=7)\n",
    "\n",
    "        # plt.suptitle(f\"{wsi_id}: {num_clusters} cluster(s), top{num_patches_per_cluster} patch(es) each\", \n",
    "        #              fontsize=12, fontweight='bold')\n",
    "\n",
    "        # Save figure\n",
    "        out_fig = os.path.join(output_dir,wsi_id,f\"{wsi_id}_topPatches.png\")\n",
    "        plt.savefig(out_fig, format='png', dpi=500, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        # Convert cluster_rows to DataFrame, store for final CSV\n",
    "        if len(cluster_rows) > 0:\n",
    "            wsi_df_rows = pd.DataFrame(cluster_rows, columns=columns)\n",
    "            results.append(wsi_df_rows)\n",
    "\n",
    "    # =====================================================================\n",
    "    # E) SAVE ALL WSIs' RESULTS TO CSV\n",
    "    # =====================================================================\n",
    "    if len(results) == 0:\n",
    "        print(\"No results to save.\")\n",
    "        return\n",
    "\n",
    "    final_df = pd.concat(results, ignore_index=True)\n",
    "    # rename the column names and specially instead of prompt number write prompt name/text\n",
    "    final_df.columns = [\"WSI_Id\", \"Label\", \"Patch_ID\", \"Crop_Index\"] + prompts + [\"Best_Caption\"]\n",
    "    out_csv = os.path.join(output_dir, \"top_patch_fivecrop_results.csv\")\n",
    "    final_df.to_csv(out_csv, index=False)\n",
    "    print(f\"All results saved => {out_csv}\")\n",
    "\n",
    "\n",
    "# Example call\n",
    "display_top_patches_with_captions_and_save_csv(\n",
    "    wsi_id_list=wsi_id_list,\n",
    "    feature_dir=feature_dir,\n",
    "    image_dir=image_dir,\n",
    "    wsi_df=wsi_df,\n",
    "    output_dir=output_dir,\n",
    "    num_clusters=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process All patches of all WSIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gc  # Garbage collection module\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def process_all_patches_with_captions_and_save_csv(\n",
    "    wsi_id_list,\n",
    "    feature_dir,\n",
    "    image_dir,\n",
    "    wsi_df,\n",
    "    output_dir\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes all patches from each WSI without selecting top patches from clusters.\n",
    "    - Loads five-crop features for all patches.\n",
    "    - Retrieves original five-crop sub-features.\n",
    "    - Generates captions for all patches and sub-crops.\n",
    "    - Saves results to CSV and creates per-patch visualizations.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    five_crop_transform = transforms.FiveCrop(size=224)\n",
    "\n",
    "    # Open the CSV file for writing\n",
    "    out_csv = os.path.join(output_dir, \"all_patches_fivecrop_results.csv\")\n",
    "    with open(out_csv, 'w') as csv_file:\n",
    "        # Write the header\n",
    "        columns = ([\"WSI_Id\", \"Label\", \"Patch_ID\", \"Crop_Index\"] +\n",
    "                   [f\"Prompt_{i+1}\" for i in range(len(prompts))] +\n",
    "                   [\"Best_Caption\"])\n",
    "        csv_file.write(','.join(columns) + '\\n')\n",
    "\n",
    "        for wsi_id in wsi_id_list:\n",
    "            print(f\"Processing WSI: {wsi_id}\")\n",
    "\n",
    "            # --- Lookup label (optional) ---\n",
    "            row = wsi_df.loc[wsi_df[\"WSI_Id\"] == wsi_id]\n",
    "            if len(row) < 1:\n",
    "                print(f\"⚠️ No label found for WSI: {wsi_id}, skipping...\")\n",
    "                continue\n",
    "            wsi_label = row.iloc[0][\"label\"]\n",
    "\n",
    "            # Create output directory for this WSI\n",
    "            wsi_output_dir = os.path.join(output_dir, wsi_id)\n",
    "            os.makedirs(wsi_output_dir, exist_ok=True)\n",
    "\n",
    "            # -------------------------------------------------------------------\n",
    "            # A) LOAD FIVE-CROP FEATURES FOR ALL PATCHES\n",
    "            # -------------------------------------------------------------------\n",
    "            feature_dir_path = os.path.join(feature_dir, wsi_id)\n",
    "            if not os.path.isdir(feature_dir_path):\n",
    "                print(f\"Feature dir not found for {wsi_id}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            feature_files = [f for f in os.listdir(feature_dir_path) if f.endswith('.pt')]\n",
    "            patch_filenames = []\n",
    "            patch_features_5crop_list = []\n",
    "\n",
    "            for ffile in feature_files:\n",
    "                path = os.path.join(feature_dir_path, ffile)\n",
    "                feat_5crops = torch.load(path).to(device)  # Move features to GPU\n",
    "                patch_features_5crop_list.append(feat_5crops)\n",
    "                patch_filenames.append(ffile.replace('.pt', '.png'))\n",
    "\n",
    "            if len(patch_features_5crop_list) == 0:\n",
    "                print(f\"No patch features for {wsi_id}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            # -------------------------------------------------------------------\n",
    "            # B) PROCESS EACH PATCH AND SAVE IMMEDIATELY\n",
    "            # -------------------------------------------------------------------\n",
    "            wsi_image_dir = os.path.join(image_dir, wsi_id)\n",
    "            if not os.path.isdir(wsi_image_dir):\n",
    "                print(f\"Image dir not found for {wsi_id}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            patch_rows = []\n",
    "\n",
    "            for patch_fname, patch_features_5crop in zip(patch_filenames, patch_features_5crop_list):\n",
    "                patch_path = os.path.join(wsi_image_dir, patch_fname)\n",
    "                try:\n",
    "                    original_img = Image.open(patch_path).convert(\"RGB\")\n",
    "                except:\n",
    "                    print(f\"Could not open {patch_path}, skipping row.\")\n",
    "                    continue\n",
    "\n",
    "                # Generate sub-crops\n",
    "                subcrop_imgs = five_crop_transform(original_img)  # tuple of 5 PIL images\n",
    "\n",
    "                # Create figure for this patch\n",
    "                fig, axes = plt.subplots(1, 6, figsize=(18, 3))  # 1 row, 6 columns\n",
    "\n",
    "                # Show original patch in first column\n",
    "                axes[0].imshow(original_img)\n",
    "                axes[0].axis('off')\n",
    "                axes[0].set_title(f\"{patch_fname}\", fontsize=9, color='red')\n",
    "\n",
    "                # For each sub-crop, calculate similarity, caption, and save result\n",
    "                for c_idx in range(5):\n",
    "                    sub_img = subcrop_imgs[c_idx]\n",
    "                    sub_feat = patch_features_5crop[c_idx].unsqueeze(0).to(device)  # shape [1, D]\n",
    "\n",
    "                    # Compute similarity on GPU\n",
    "                    with torch.inference_mode():\n",
    "                        sim_scores = (sub_feat @ text_embeddings.T).squeeze(0)\n",
    "                    ranked_scores, ranked_idx = torch.sort(sim_scores, descending=True)\n",
    "                    best_prompt_idx = ranked_idx[0].item()\n",
    "                    best_caption = prompts[best_prompt_idx]\n",
    "                    best_score = ranked_scores[0].item()  # Extract best similarity score\n",
    "\n",
    "                    # Show sub-crop\n",
    "                    ax = axes[c_idx + 1]\n",
    "                    ax.imshow(sub_img)\n",
    "                    ax.axis('off')\n",
    "\n",
    "                    # Print caption as title\n",
    "                    short_caption = best_caption[:35] + \"...\" if len(best_caption) > 35 else best_caption\n",
    "                    ax.set_title(f\"Crop {c_idx}, {short_caption}\", fontsize=8, color='blue')\n",
    "\n",
    "                    # Draw similarity score on the image\n",
    "                    pil_sub_img = sub_img.copy()\n",
    "                    draw = ImageDraw.Draw(pil_sub_img)\n",
    "                    font = ImageFont.load_default(10)\n",
    "                    draw.text((5, 5), f\"{best_score:.2f}\", fill=\"blue\", font=font)\n",
    "                    ax.imshow(pil_sub_img)\n",
    "\n",
    "                    # Save row for CSV\n",
    "                    row_data = [\n",
    "                        wsi_id,                      # WSI_Id\n",
    "                        wsi_label,                   # Label\n",
    "                        patch_fname,                 # Patch_ID\n",
    "                        c_idx                        # Crop index\n",
    "                    ]\n",
    "                    # Add each prompt's sim score\n",
    "                    row_data.extend(sim_scores.cpu().tolist())  # Move scores back to CPU for saving\n",
    "                    # Add best caption\n",
    "                    row_data.append(best_caption)\n",
    "                    patch_rows.append(row_data)\n",
    "\n",
    "                # Save figure\n",
    "                patch_output_path = os.path.join(wsi_output_dir, f\"{patch_fname.replace('.png', '_five_crops.png')}\")\n",
    "                plt.savefig(patch_output_path, format='png', dpi=500, bbox_inches='tight')\n",
    "                plt.close()\n",
    "\n",
    "            # Write the results of this WSI to the CSV file\n",
    "            if len(patch_rows) > 0:\n",
    "                for row in patch_rows:\n",
    "                    csv_file.write(','.join(map(str, row)) + '\\n')\n",
    "\n",
    "            # Free up memory explicitly\n",
    "            del patch_rows, patch_features_5crop_list, patch_filenames\n",
    "            torch.cuda.empty_cache()  # Clear GPU memory\n",
    "            gc.collect()  # Force garbage collection\n",
    "\n",
    "    print(f\"All results saved => {out_csv}\")\n",
    "\n",
    "# Call the updated function\n",
    "process_all_patches_with_captions_and_save_csv(\n",
    "    wsi_id_list=wsi_id_list,\n",
    "    feature_dir=feature_dir,\n",
    "    image_dir=image_dir,\n",
    "    wsi_df=wsi_df,\n",
    "    output_dir=output_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "MSIH       60\n",
      "nonMSIH    45\n",
      "Name: count, dtype: int64\n",
      "4\n",
      "5\n",
      "Count of Patches against each promt in MSIH\n",
      "Best_Caption\n",
      "Adipose          33\n",
      "Debris           19\n",
      "Smooth Muscle     7\n",
      "Mucin             1\n",
      "Name: count, dtype: int64\n",
      "Count of Patches against each promt in nonMSIH\n",
      "Best_Caption\n",
      "Debris               16\n",
      "Smooth Muscle        14\n",
      "Adipose              11\n",
      "Lymphocytes           2\n",
      "Connective tissue     2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# read file from the output directory top_patch_results_top1_2cluster.csv\n",
    "results_file = os.path.join(output_dir, \"all_patches_fivecrop_results.csv\")\n",
    "# read the file\n",
    "df = pd.read_csv(results_file)\n",
    "df.head()\n",
    "# print the count of MSIH and nonMSIH from the label column\n",
    "print(df[\"Label\"].value_counts())\n",
    "# separate the msih and nonmsih data\n",
    "msih = df[df[\"Label\"] == \"MSIH\"]\n",
    "nonmsih = df[df[\"Label\"] == \"nonMSIH\"]\n",
    "# now in both count the unique count of best caption column\n",
    "print(msih[\"Best_Caption\"].nunique())\n",
    "print(nonmsih[\"Best_Caption\"].nunique())\n",
    "# now we will count the best caption for each label\n",
    "print(f'Count of Patches against each promt in MSIH')\n",
    "print(msih[\"Best_Caption\"].value_counts())\n",
    "print(f'Count of Patches against each promt in nonMSIH')\n",
    "print(nonmsih[\"Best_Caption\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the format/shape of top patches output csv file from depthwise to row-wise for each WSI-ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the input file from the output_path the name is top3_prompts_2cluster_top1_patch.csv\n",
    "input_path = os.path.join(output_dir, \"top3_prompts_2cluster_top1_patch.csv\")\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Function to extract unique captions while preserving their first-occurrence order\n",
    "def unique_preserve_order(text_series):\n",
    "    unique_caps = []\n",
    "    # Iterate over each text in the series\n",
    "    for text in text_series:\n",
    "        # Split each cell by semicolon to get individual captions\n",
    "        parts = text.split(\";\")\n",
    "        for part in parts:\n",
    "            cap = part.strip()\n",
    "            if cap and cap not in unique_caps:\n",
    "                unique_caps.append(cap)\n",
    "    # Join back into a semicolon-separated string\n",
    "    return \"; \".join(unique_caps)\n",
    "\n",
    "results = []\n",
    "\n",
    "# Group the data by WSI_Id.\n",
    "# It is assumed that for each WSI_Id the first 5 rows are the top patch's crops,\n",
    "# and the next 5 rows are the bottom patch's crops.\n",
    "for wsi_id, group in df.groupby(\"WSI_Id\"):\n",
    "    group = group.reset_index(drop=True)\n",
    "    \n",
    "    # Extract top patch (rows 0 to 4) and bottom patch (rows 5 to 9)\n",
    "    top_crops = group.iloc[0:5][\"Best_Captions\"]\n",
    "    bottom_crops = group.iloc[5:10][\"Best_Captions\"]\n",
    "    \n",
    "    # Get unique captions, preserving the order of first appearance.\n",
    "    top_str = unique_preserve_order(top_crops)\n",
    "    bottom_str = unique_preserve_order(bottom_crops)\n",
    "    \n",
    "    # Append the results. Here, the Agree, Missed, and Remarks columns are set as empty.\n",
    "    results.append({\n",
    "        \"Final review 5 crop\": wsi_id,\n",
    "        \"Top\": top_str,\n",
    "        \"Agree\": \"\",\n",
    "        \"Missed\": \"\",\n",
    "        \"Remarks\": \"\",\n",
    "        \"Bottom\": bottom_str,\n",
    "        \"Agree_bottom\": \"\",\n",
    "        \"Missed_bottom\": \"\"\n",
    "    })\n",
    "\n",
    "# Create the final DataFrame\n",
    "final_df = pd.DataFrame(results)\n",
    "\n",
    "# Optional: save the output to a CSV file or print it.\n",
    "output_file_path = os.path.join(output_dir, \"reshaped_top3_prompts_2cluster_top1_patch.csv\")\n",
    "\n",
    "final_df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcga",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
